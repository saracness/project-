# ğŸ§  Yapay Zeka Beyinleri - AI Brains Guide

## Mikroorganizmalara FarklÄ± AI Modelleri ile Zeka Verildi!

Her grup farklÄ± bir yapay zeka algoritmasÄ± kullanarak hayatta kalmaya Ã§alÄ±ÅŸÄ±yor!

---

## ğŸ¯ Implemented AI Models

### 1. **Q-Learning Brain** (Reinforcement Learning)
**Dosya:** `microlife/ml/brain_rl.py` â†’ `QLearningBrain`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- Table-based reinforcement learning
- State'leri discretize eder (sÃ¼rekli â†’ ayrÄ±k)
- Q-table ile en iyi aksiyonu Ã¶ÄŸrenir
- Epsilon-greedy exploration

**KullanÄ±m:**
```python
from microlife.ml.brain_rl import QLearningBrain

brain = QLearningBrain(learning_rate=0.1, epsilon=0.3)
action = brain.decide_action(state)
brain.learn(state, action, reward, next_state, done)
```

**Avantaj:** Basit, anlaÅŸÄ±lÄ±r, garanti convergence
**Dezavantaj:** BÃ¼yÃ¼k state space'lerde yavaÅŸ

---

### 2. **DQN Brain** (Deep Q-Network)
**Dosya:** `microlife/ml/brain_rl.py` â†’ `DQNBrain`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- Neural network ile Q-values tahmin eder
- Experience replay ile Ã¶ÄŸrenir
- Continuous state space'ler iÃ§in iyi

**KullanÄ±m:**
```python
from microlife.ml.brain_rl import DQNBrain

brain = DQNBrain(state_size=7, hidden_size=32)
action = brain.decide_action(state)
brain.learn(state, action, reward, next_state, done)
```

**Avantaj:** Scalable, complex patterns
**Dezavantaj:** Training sÃ¼resi uzun

---

### 3. **Double DQN Brain** (Modern RL)
**Dosya:** `microlife/ml/brain_rl.py` â†’ `DoubleDQNBrain`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- DQN + Target network
- Overestimation bias'Ä± azaltÄ±r
- State-of-the-art RL tekniÄŸi

**KullanÄ±m:**
```python
from microlife.ml.brain_rl import DoubleDQNBrain

brain = DoubleDQNBrain()
```

**Avantaj:** En stable RL yaklaÅŸÄ±mÄ±
**Dezavantaj:** Memory intensive

---

### 4. **CNN Brain** (Convolutional Neural Network)
**Dosya:** `microlife/ml/brain_cnn.py` â†’ `CNNBrain`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- Ã‡evreyi 2D grid olarak gÃ¶rÃ¼r (visual perception!)
- Convolution layers ile pattern detection
- Biyolojik gÃ¶rsel korteksten esinlenmiÅŸ

**KullanÄ±m:**
```python
from microlife.ml.brain_cnn import CNNBrain

brain = CNNBrain(grid_size=20)
action = brain.decide_action(state)
```

**Ã–zellik:** OrganizmanÄ±n "gÃ¶rdÃ¼ÄŸÃ¼" 20x20 grid:
- Food â†’ 1.0
- Obstacles â†’ -0.5
- Temperature zones â†’ -0.5

**Avantaj:** Spatial patterns, vision-like
**Dezavantaj:** Computationally expensive

---

### 5. **ResNet-CNN Brain** (Residual Networks)
**Dosya:** `microlife/ml/brain_cnn.py` â†’ `ResidualCNNBrain`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- CNN + skip connections
- Modern computer vision'dan
- Daha derin Ã¶ÄŸrenme

**KullanÄ±m:**
```python
from microlife.ml.brain_cnn import ResidualCNNBrain

brain = ResidualCNNBrain(grid_size=20)
```

**Avantaj:** Deeper learning, better gradients

---

### 6. **Genetic Algorithm Brain** (Evolution)
**Dosya:** `microlife/ml/brain_evolutionary.py` â†’ `GeneticAlgorithmBrain`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- Genome (20 gene) davranÄ±ÅŸÄ± kodlar
- Mutation ile deÄŸiÅŸir
- Crossover ile Ã§ocuk Ã¼retir
- DoÄŸal seleksiyon gibi!

**Genom YapÄ±sÄ±:**
- Gene 0-7: YÃ¶n tercihleri
- Gene 8-11: Enerji bazlÄ± davranÄ±ÅŸ
- Gene 12-15: Yemek arama
- Gene 16-19: Risk alma

**KullanÄ±m:**
```python
from microlife.ml.brain_evolutionary import GeneticAlgorithmBrain

brain = GeneticAlgorithmBrain(genome_size=20, mutation_rate=0.1)
action = brain.decide_action(state)

# Evolution
brain.mutate()
child = brain1.crossover(brain2)
```

**Avantaj:** Biyolojik, evrimsel, explainable
**Dezavantaj:** YavaÅŸ convergence

---

### 7. **NEAT Brain** (NeuroEvolution)
**Dosya:** `microlife/ml/brain_evolutionary.py` â†’ `NEATBrain`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- Network STRUCTURE'Ä± da evolve eder!
- BaÅŸlangÄ±Ã§ta minimal network
- Mutation: node ekle, connection ekle
- Weight evolution + topology evolution

**KullanÄ±m:**
```python
from microlife.ml.brain_evolutionary import NEATBrain

brain = NEATBrain(input_size=7, output_size=9)
action = brain.decide_action(state)

# Evolve structure
brain.mutate(add_node_prob=0.03, add_conn_prob=0.05)
```

**Avantaj:** Discovers optimal architecture
**Dezavantaj:** Complex, many hyperparameters

---

### 8. **CMA-ES Brain** (Evolution Strategy)
**Dosya:** `microlife/ml/brain_evolutionary.py` â†’ `CMAESBrain`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- Covariance Matrix Adaptation
- Evolution strategy (modern!)
- Distribution-based optimization
- Biyoloji araÅŸtÄ±rmalarÄ±nda Ã§ok kullanÄ±lÄ±r

**KullanÄ±m:**
```python
from microlife.ml.brain_evolutionary import CMAESBrain

brain = CMAESBrain(param_size=20)
action = brain.decide_action(state)

# Update distribution
brain.update_distribution(successful_params, fitness_values)
```

**Avantaj:** State-of-the-art evolution
**Dezavantaj:** Population-based (needs many organisms)

---

## ğŸ“Š Model Comparison Table

| Model | Type | Learning | Speed | Memory | Best For |
|-------|------|----------|-------|--------|----------|
| Q-Learning | RL | Online | Fast | Low | Simple envs |
| DQN | Deep RL | Batch | Medium | High | Complex states |
| Double DQN | Deep RL | Batch | Medium | High | Stable learning |
| CNN | Visual | Batch | Slow | High | Spatial tasks |
| ResNet-CNN | Visual | Batch | Slow | Very High | Deep vision |
| Genetic Alg | Evolution | Generational | Slow | Low | Interpretable |
| NEAT | Neuroevolution | Generational | Medium | Medium | Architecture search |
| CMA-ES | Evolution Strategy | Generational | Medium | Medium | Parameter tuning |

---

## ğŸ® How to Use Different Brains

### Organizmalara Brain Atama:

```python
from microlife.simulation.organism import Organism
from microlife.ml.brain_rl import QLearningBrain, DQNBrain
from microlife.ml.brain_cnn import CNNBrain
from microlife.ml.brain_evolutionary import GeneticAlgorithmBrain, NEATBrain

# Create organisms with different brains
org1 = Organism(100, 100)
org1.brain = QLearningBrain()

org2 = Organism(200, 200)
org2.brain = DQNBrain()

org3 = Organism(300, 300)
org3.brain = CNNBrain(grid_size=20)

org4 = Organism(400, 400)
org4.brain = GeneticAlgorithmBrain()

org5 = Organism(150, 150)
org5.brain = NEATBrain()

# Simulation loop
for timestep in range(1000):
    for org in [org1, org2, org3, org4, org5]:
        # Get state
        state = org.get_state()

        # AI decides action
        action = org.brain.decide_action(state)

        # Move based on AI decision
        dx, dy = action['move_direction']
        org.x += dx * org.speed
        org.y += dy * org.speed

        # Calculate reward
        reward = org.brain.calculate_reward(old_state, state, action)

        # Learn
        org.brain.learn(old_state, action, reward, state, not org.alive)
```

---

## ğŸ† AI Battle Arena - Who Wins?

### Test Scenarios:

1. **Survival Challenge**
   - 50 organisms, 5 of each brain type
   - Limited food
   - Temperature zones
   - Winner: Most survivors after 1000 timesteps

2. **Speed Test**
   - Which brain makes fastest decisions?
   - Winner: DQN (forward pass only)

3. **Learning Speed**
   - Which learns fastest?
   - Winner: Q-Learning (simple updates)

4. **Complex Environment**
   - Obstacles, temp zones, moving food
   - Winner: CNN or NEAT (spatial reasoning)

5. **Evolution Test**
   - 10 generations
   - Winner: CMA-ES or NEAT (best evolution)

---

## ğŸ”¬ Biological Inspiration

### Which Models Biologists Use:

1. **Genetic Algorithms** âœ…
   - Evolution simulation
   - Population genetics
   - Natural selection studies

2. **NEAT** âœ…
   - Brain evolution studies
   - Artificial life research
   - Behavioral ecology

3. **CMA-ES** âœ…
   - Parameter estimation
   - Evolutionary dynamics
   - Optimization in biology

4. **CNN** âœ…
   - Visual system modeling
   - Neural cortex simulation
   - Sensory processing

5. **Reinforcement Learning** âœ…
   - Animal learning
   - Behavioral neuroscience
   - Dopamine reward systems

---

## ğŸ“ File Structure

```
microlife/ml/
â”œâ”€â”€ brain_base.py           â†’ Base Brain interface
â”œâ”€â”€ brain_rl.py             â†’ Q-Learning, DQN, Double DQN
â”œâ”€â”€ brain_cnn.py            â†’ CNN, ResNet-CNN
â””â”€â”€ brain_evolutionary.py   â†’ GA, NEAT, CMA-ES
```

**Total:** 8 different AI models implemented!

---

## ğŸš€ Next: Create Battle Arena Demo

```bash
python demo_ai_battle.py
```

See all AI models compete in real-time!

---

## ğŸ“ Learning Paths

### Beginner:
1. Start with **Q-Learning** (simplest)
2. Try **Genetic Algorithm** (intuitive)

### Intermediate:
3. **DQN** (neural networks)
4. **CNN** (visual perception)

### Advanced:
5. **NEAT** (topology evolution)
6. **CMA-ES** (modern evolution)
7. **Double DQN** (state-of-the-art RL)

---

## ğŸ’¡ Key Insights

### Learning-Based (RL):
- Learn during lifetime
- Adapt to environment changes
- Fast adaptation

### Evolution-Based (GA, NEAT, CMA-ES):
- Learn across generations
- Slower but more general
- Biological realism

### Hybrid (Best of both):
- Evolution for structure
- RL for weights
- Future work!

---

**Åimdi mikroorganizmalar gerÃ§ekten akÄ±llÄ±! 8 farklÄ± AI modeli! ğŸ§ ğŸ¦ **

Hangisi en iyi? Test edin ve gÃ¶rÃ¼n! ğŸ†
