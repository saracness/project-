# Scientific Analysis & Auto-Reporting System

## ðŸ”¬ Overview

Professional-grade scientific data collection, analysis, and automatic reporting system for research and publication.

## ðŸŽ¯ Features

### 1. Background Data Logger
- **Continuous data collection** - Non-intrusive background logging
- **Multi-threaded** - Doesn't block simulation
- **Configurable sampling rate** - Every N steps/seconds
- **Memory efficient** - Automatic data pruning
- **Persistent storage** - SQLite database

### 2. Scientific Plotting
- **Publication-quality graphs** - High DPI, vector graphics
- **Multiple plot types**:
  - Time-series plots
  - Population dynamics
  - Histograms & distributions
  - Scatter plots & correlations
  - Box plots & violin plots
  - Heatmaps & contour plots
- **Professional styling** - Seaborn themes, custom palettes
- **LaTeX support** - Math equations in labels

### 3. Statistical Analysis
- **Descriptive statistics** - Mean, median, std, quartiles
- **Hypothesis testing** - t-tests, ANOVA
- **Correlation analysis** - Pearson, Spearman
- **Trend detection** - Linear regression, polynomial fitting
- **Anomaly detection** - Outlier identification
- **Time-series analysis** - Seasonality, autocorrelation

### 4. Auto-Report Generation
- **PDF reports** - Professional LaTeX-based reports
- **HTML dashboards** - Interactive web reports
- **Automatic scheduling** - Generate every N minutes/episodes
- **Custom templates** - Configurable report layouts
- **Multi-page reports** - Executive summary + detailed analysis

### 5. Real-Time Monitoring
- **Live dashboards** - Web-based real-time monitoring
- **Alerts** - Anomaly notifications
- **Export formats** - CSV, JSON, HDF5, Parquet

## ðŸ“Š Scientific Graphs

### Population Dynamics
```
Population Over Time
1000 â”¤                    â•­â”€â”€â”€â”€â”€â•®
 800 â”¤        â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯     â•°â”€â”€â•®
 600 â”¤   â•­â”€â”€â”€â”€â•¯                   â•°â”€
 400 â”¤â•­â”€â”€â•¯
 200 â”¤â•¯
   0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
     0     200    400    600    800
               Episodes
```

### Energy Distribution
```
Energy Distribution (Histogram)
Freq
 80 â”¤    â–ˆâ–ˆ
 60 â”¤   â–ˆâ–ˆâ–ˆâ–ˆ
 40 â”¤  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
 20 â”¤ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
  0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
    0  25 50 75 100
         Energy
```

### Correlation Matrix
```
       Energy  Age  Speed
Energy  1.00  0.45  0.32
Age     0.45  1.00 -0.12
Speed   0.32 -0.12  1.00
```

## ðŸ—ï¸ Architecture

### Components

1. **DataLogger** - Background data collection
2. **ScientificPlotter** - Publication-quality plots
3. **StatisticalAnalyzer** - Statistical analysis
4. **ReportGenerator** - PDF/HTML report creation
5. **TimeSeriesAnalyzer** - Time-series specific analysis
6. **ExperimentTracker** - Multi-run experiment tracking

### Data Flow

```
Simulation Loop
    â†“
DataLogger (background thread)
    â†“
Database Storage (SQLite)
    â†“
Analysis Pipeline (scheduled)
    â†“
Graph Generation
    â†“
Report Creation
    â†“
Auto-Save (PDF/PNG/HTML)
```

## ðŸ“ File Structure

```
microlife/analytics/
â”œâ”€â”€ data_logger.py          # Background data collection
â”œâ”€â”€ scientific_plotter.py   # Publication-quality plots
â”œâ”€â”€ statistical_analyzer.py # Statistical analysis
â”œâ”€â”€ report_generator.py     # PDF/HTML reports
â”œâ”€â”€ time_series_analyzer.py # Time-series analysis
â””â”€â”€ experiment_tracker.py   # Multi-experiment tracking

outputs/
â”œâ”€â”€ graphs/                 # Auto-saved graphs
â”‚   â”œâ”€â”€ population_dynamics.png
â”‚   â”œâ”€â”€ energy_distribution.png
â”‚   â””â”€â”€ survival_rates.png
â”œâ”€â”€ reports/                # Generated reports
â”‚   â”œâ”€â”€ experiment_001.pdf
â”‚   â””â”€â”€ dashboard.html
â””â”€â”€ data/                   # Raw data
    â”œâ”€â”€ metrics.db          # SQLite database
    â””â”€â”€ experiment_001.csv
```

## ðŸš€ Usage

### Basic Auto-Logging

```python
from microlife.analytics import DataLogger, ScientificPlotter

# Start background logger
logger = DataLogger(
    db_path='outputs/data/metrics.db',
    sampling_rate=10,  # Log every 10 steps
    auto_save_graphs=True,
    graph_interval=100  # Save graphs every 100 episodes
)

# Run simulation
for episode in range(1000):
    # Simulation step...

    # Logger automatically collects data in background
    logger.log_step(
        episode=episode,
        organisms=organisms,
        environment=environment
    )

    # Graphs are automatically saved to outputs/graphs/
```

### Auto-Report Generation

```python
from microlife.analytics import ReportGenerator

# Configure auto-reporting
report_gen = ReportGenerator(
    output_dir='outputs/reports/',
    template='scientific',
    auto_generate=True,
    interval=500  # Generate report every 500 episodes
)

# Reports are automatically created during simulation
```

### Advanced Scientific Analysis

```python
from microlife.analytics import StatisticalAnalyzer

# Analyze collected data
analyzer = StatisticalAnalyzer(db_path='outputs/data/metrics.db')

# Generate comprehensive analysis
results = analyzer.analyze_all()
print(results['population_trends'])
print(results['correlations'])
print(results['statistical_tests'])

# Save analysis to report
analyzer.export_report('outputs/reports/analysis.pdf')
```

## ðŸ“ˆ Scientific Plot Types

### 1. Population Dynamics
- **Total population over time**
- **Birth/death rates**
- **Age distribution evolution**
- **Species diversity (if applicable)**

### 2. Energy & Resources
- **Energy distribution histograms**
- **Food consumption rates**
- **Energy efficiency trends**
- **Resource competition heatmaps**

### 3. Behavioral Analysis
- **Movement patterns**
- **Decision-making distributions**
- **Learning curves (AI organisms)**
- **Social interaction graphs**

### 4. Performance Metrics
- **FPS over time**
- **Computation time breakdown**
- **Memory usage**
- **GPU utilization**

### 5. Comparative Analysis
- **Algorithm comparison (A/B testing)**
- **Parameter sensitivity analysis**
- **Multi-run confidence intervals**
- **Statistical significance tests**

## ðŸ” Statistical Analysis Features

### Descriptive Statistics
```python
stats = analyzer.get_descriptive_stats('energy')
# Output:
{
    'mean': 52.3,
    'median': 50.1,
    'std': 15.2,
    'min': 10.0,
    'max': 100.0,
    'q25': 40.2,
    'q75': 65.8,
    'skewness': 0.15,
    'kurtosis': -0.32
}
```

### Correlation Analysis
```python
correlations = analyzer.correlation_matrix(['energy', 'age', 'speed'])
# Generates correlation heatmap with significance levels
```

### Trend Detection
```python
trend = analyzer.detect_trend('population', method='linear')
# Returns: slope, intercept, r_squared, p_value
```

### Hypothesis Testing
```python
result = analyzer.t_test(
    group1='ai_organisms_energy',
    group2='simple_organisms_energy'
)
# Returns: t_statistic, p_value, significant
```

## ðŸ“„ Report Templates

### Scientific Report (PDF)
- **Title page** - Experiment metadata
- **Executive summary** - Key findings
- **Methods** - Simulation parameters
- **Results** - Statistical analysis + graphs
- **Discussion** - Interpretation
- **Appendix** - Raw data tables

### Dashboard (HTML)
- **Interactive plots** - Plotly.js
- **Real-time updates** - WebSocket support
- **Filterable data** - Date range, metrics
- **Downloadable** - Export to CSV/Excel

## âš™ï¸ Configuration

```python
config = {
    'data_logger': {
        'enabled': True,
        'sampling_rate': 10,
        'buffer_size': 1000,
        'auto_flush': True,
        'compress': True,
    },
    'plotting': {
        'style': 'seaborn-darkgrid',
        'dpi': 300,
        'format': 'png',  # 'png', 'svg', 'pdf'
        'figsize': (12, 8),
        'font_size': 12,
        'use_latex': False,
    },
    'reports': {
        'auto_generate': True,
        'interval': 500,
        'format': 'pdf',  # 'pdf', 'html'
        'include_raw_data': False,
        'template': 'scientific',
    },
    'analysis': {
        'confidence_level': 0.95,
        'outlier_threshold': 3.0,  # std deviations
        'trend_method': 'linear',
    }
}
```

## ðŸŽ“ Use Cases

### Research
- **Publish papers** - Generate publication-ready figures
- **Statistical validation** - Hypothesis testing
- **Reproducibility** - Complete data logging

### Education
- **Teaching material** - Demonstrate concepts
- **Student projects** - Automatic grading data
- **Interactive learning** - Real-time dashboards

### Development
- **Algorithm comparison** - A/B testing
- **Performance monitoring** - Bottleneck detection
- **Regression testing** - Detect changes

### Demonstration
- **Project showcase** - Professional reports
- **Investor presentations** - Executive summaries
- **Documentation** - Automatic graph generation

## ðŸ”¬ Advanced Features

### Multi-Experiment Tracking
```python
tracker = ExperimentTracker('outputs/experiments/')

# Run multiple experiments with different parameters
for learning_rate in [0.001, 0.01, 0.1]:
    experiment = tracker.start_experiment(
        name=f'lr_{learning_rate}',
        params={'learning_rate': learning_rate}
    )

    # Run simulation...

    experiment.finish()

# Compare all experiments
tracker.generate_comparison_report()
```

### Custom Analysis Pipelines
```python
from microlife.analytics import AnalysisPipeline

pipeline = AnalysisPipeline()
pipeline.add_step('load_data', db_path='metrics.db')
pipeline.add_step('filter', lambda x: x['episode'] > 100)
pipeline.add_step('compute_stats', metrics=['mean', 'std'])
pipeline.add_step('plot', plot_type='timeseries')
pipeline.add_step('save', format='pdf')

# Run pipeline
pipeline.execute()
```

### Real-Time Web Dashboard
```python
from microlife.analytics import WebDashboard

# Start web server
dashboard = WebDashboard(port=8080)
dashboard.start()

# Access at http://localhost:8080
# Live updating graphs, interactive controls
```

## ðŸ“Š Performance

- **Logging overhead**: <1ms per step
- **Graph generation**: ~2s for complex multi-panel figures
- **Report generation**: ~10s for PDF with 20 graphs
- **Database size**: ~1MB per 10k episodes
- **Memory usage**: <50MB for logger

## ðŸ› ï¸ Dependencies

```bash
pip install numpy pandas matplotlib seaborn scipy
pip install scikit-learn sqlalchemy plotly
pip install reportlab jinja2 weasyprint
```

## ðŸ“š Example Output

### Auto-Generated Report
```
Experiment Report: lr_0.001
Generated: 2025-01-18 12:34:56

EXECUTIVE SUMMARY
-----------------
- Total episodes: 1000
- Average population: 245 Â± 32
- Energy efficiency: +15% vs baseline
- AI organisms survival: 78%

KEY FINDINGS
------------
1. Population stabilized after episode 300
2. Strong correlation (r=0.82) between energy and age
3. Significant improvement in learning rate (p<0.001)

[Multiple publication-quality graphs inserted here]

STATISTICAL ANALYSIS
--------------------
[Detailed statistical tables and tests]
```

---

**Next:** Implementation of all components! ðŸš€
